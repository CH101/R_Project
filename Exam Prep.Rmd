---
title: "Final Exam Prep"
output: word_document
---

Clean work environment
```{r, message=FALSE}
rm(list = ls())
```

Activate Packages that are necessary to analyse the data set.
```{r, message=FALSE}
library(data.table)
library(ggplot2)
library(stargazer)
library(sandwich)
library(lmtest)
library(plm)
library(Formula)
library(doBy)
library(mfx)
```

lm model with missing data: 
na.exclude or na.ommit


```{r}
load("data_name.RData")
dt.political_campaign <- data.table(data_name)
rm(data_name)
```

#Summary statistics
```{r}
head(data_name)
names(data_name)
data_name[,unique(year)] 
dt.ez[,table(ez, year)] #when did treatment start?

stargazer(data_name, type = "text", 
          nobs = FALSE, mean.sd = TRUE, median = TRUE, iqr = TRUE, no.space = TRUE,  omit.summary.stat = c("p25","p75"))
summary(data_name[, list(variable1, variable2, variable3)])

ins <- dt.medical[suppins==1]
no.ins <- dt.medical[suppins==0]
stargazer(ins, type = "text")
stargazer(no.ins, type = "text")

dt.ez[,unique(year)] #Only the years
```

#Missing data
```{rd}
t.fastfood[, missing := ifelse(is.na(hrsopen), 1,
                                ifelse(is.na(pmeal)  , 1,
                                       ifelse(is.na(fracft) , 1, 0)))]
dt.fastfood[, missing := max(missing), by = id]
dt.fastfood <- dt.fastfood[missing ==  0, ]
dt.fastfood[, missing := NULL]
# Alternatively, using lapply
#dt.fastfood[, missing:= rowSums(data.frame(lapply(dt.fastfood, function(x) is.na(x))))]
#dt.fastfood[, missing:= max(missing), by = id]
```

#Stargazer output regression models
```{r, warning=FALSE, message=FALSE}
#plm: "pooling", "within" or "fd"
lm11 <- plm(pmeal ~ time + state + time*state, data = dt.fastfood
            , model = "pooling"
            , index = c('id','time')) #identifies which variables comprise the panal structure: first variable for individual observation, then the time variable
stargazer(lm3,lm4, type = "text", no.space = TRUE, omit.stat = c("f","ser")
```

#Add a new variable:
```{r}
data_name[, male_string := monthlypay/]
```

#Difference in difference model: create table
$$ (Treated_{After} - Treated_{Before}) - (Control_{After} - Control_{Before}) $$
```{r, warning=FALSE, message=FALSE}
dt.bf.aft <- dt.fastfood[, list(       # Create a list of the columns of your new table 
    mean_emptot     = mean(emptot  , na.rm = TRUE)
  , mean_wage       = mean(wage    , na.rm = TRUE)
  , mean_pmeal      = mean(pmeal   , na.rm = TRUE)
  , mean_hrsopen    = mean(hrsopen , na.rm = TRUE)
 ), by=list(state, time)]            # Specifiy the list of grouping variables
dt.bf.aft

#Control with interaction term:
lm1 <- plm(emptot ~ time + state + time*state, data = dt.fastfood, model = "pooling", 
           index = c('id','time'))
```
Are the coefficients statistically significant? How do we interpret the regression coefficients?

- emptot00: average FTE employment at T0 in Pennsylvania ($\beta_0$)
- emptot01: average FTE employment at T1 in Pennsylvania ($\beta_0$ + $\beta_1$)
- emptot10: average FTE employment at T0 in New Jersey ($\beta_0$ + $\beta_2$)
- emptot11: average FTE employment at T1 in New Jersey ($\beta_0$ + $\beta_1$ + $\beta_2$ + $\beta_3$)

#Data table
```{r}
dt.tmp <- data.table(dt.apples[order(male, buy_eco), .N, by = list(male, buy_eco)])
dt.tmp <- dt.tmp[, prop := N / sum(N), by = male]
dt.tmp[, male_string := ifelse(male == 1, "Male", "Female")]
dt.tmp[, buyeco_string := ifelse(buy_eco == 1, "Yes", "No")]
dt.tmp
```

#Is panel data balanced? How to order panel data
Per definition, a panel data set is balanced, if we have the same number of time periods for each observation.
(When T is small relative to N, we should include a dummy variable for each time period to account for secular changes that are nott being modeled.)

```{r, warning=FALSE, message=FALSE}
dt.panel <- dt.panel[order(state,year)] #order panel data

data_name[,.N,by=year]
# or
data_name[,.N,by=city]
```

Total number of observations after applying the first difference model is $N(T-1)$

#Pooled OLS als Vorstufe zu FD und FE
```{r, warning=FALSE, message=FALSE, eval=TRUE,}
#Inlcude dummies for years and Factor city to reduce bias of not removing time constant effects
out.pool <- plm(luclms ~ ez + d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + factor(city)
                  , data = dt.ez
                  , index = c('city','year')
                  , model = 'pooling') #pooled cross-section
stargazer(out.pool, type = "text", no.space = TRUE)
```

#First difference and Fixed Effects: Eliminate time constant variables
The unobserved effect $a_i$ represents fixed factors that affect the economic climate in city $i$. Because enterprise zone designation was not determined randomly (enterprise zones are usually economically depressed areas), it is likely that $ez_{it}$ and $a_i$ are positively correlated (high $a_i$ means higher unemployment claims, which lead to a higher chance of being given an EZ). Thus, we are in a situation where we should take first-differences on the equation to eliminate $a_i$.

##First difference
Key assumptions:
- The change in unobserved heterogeneity ($\nu_t = u_{it} - u_{it-1}$) is uncorrelated with the changes in the independent variables ($\delta x_{it} = x_{it}-x_{it-1}$). You should think about this problem and whether or not this assumption is reasonable.
- Also, there must be variation in the changes, since we substract the time periods
```{r, echo=TRUE,message=FALSE}
out.fd <-plm(luclms ~ 0 + ez + d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88
            , data= dt.ez
            , index=c('city','year')
            , model='fd')
stargazer(out.fd, type = "text", no.space = TRUE)

#Interpretation of Log-Level: 
#The dependent variable in this equation, the change in `log(uclmsit)`, is the approximate annual growth rate in unemployment claims from year $t-1$ to $t$.
(coeffs <- coefficients(out.fd))
(treat.effect <- (exp(coeffs[1])-1)*100)
```

##Fixed effects
```{r}
out.fe <-plm(   luclms ~ ez + d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88
                , data= dt.ez
                , index=c('city','year')
                , model='within')
stargazer(out.fe, type = "text", no.space = TRUE)
```
If we compare only two different time periods, the estimates of the fixed-effects model and the first difference model are exaclty the same. If we increase the number of time periods, the fixed effects estimates will be more efficient, as long as we assume that the classical assumptions hold. However, if the model has significant serial correlation, then the estimates of first difference may be better. 

!Rewirte:
The fixed-effects estimator is the same as the pooled OLS with all the dummies (remember we added them to correct for the bias?). So, we can do it like this (using the dummies).

#Test for serial correlation:
Serial correlation appears always then, when the residuals are correlated over time. Since the analysed data set is a panel data set, it is possible to have serial correlation, because we analyse the same observations over several time periods. 
There are two different types of serial correlation : positive and negative correlation. Positive Serial Correlation appear if the residuals of two subsewuent time periods are positively correlated. Negative serial correlation describes a similar condition, but where correlation of the residuals is negative.
Significant positive serial correlation leads to overestimated standard errors and underestimated t-statistics. That means, 

The consequences of Positive Serial Correlation are:

- Standard errors are underestimated
- t-statistics are inflated
- Type-I error increases (false positive, you incorrectly reject the null)

The consequences of Negative Serial Correlation are:

- Standard errors are overstated
- t-statistics are understated
- Type-II error increases (false negative, you incorrectly do not reject the null)

Positive serial correlation is a more serious problem than negative serial correlation. Usually, we will worry about negative serial correlation if it is "large" ($< -0.2$). 
 
$(y-yhat)$
In order to test for serially correlation, we need to calculate if there is significant corrlelation between the time dependent error term in t and in t-1. 
```{r, message=FALSE}
out.insurance <- lm_fix
u <- residuals(out.insurance)
dt.panel[year!=1991, u:= u]
out.u <- plm(u~lag(u,1)
             , data = dt.panel
             , index = c("state","year")
             , model = "within")
stargazer(out.u,type = "text", no.space = TRUE, omit.stat = c("f","ser"))
```


#Linear probability model
The linear probability model takes the following equation:
$$P(y=1|\mathbf x)=E(y|\mathbf x)=\beta_0 + \beta_1 x_1 + ... + \beta_k x_k$$

#Logit&Probit
Since we cant directly interpret the coefficients from the stargazer output of logit&probit, we have to calculate either PEA or APE.
mfxlogit or mfxprobit
But we cant interpret discret variables as well as non linear variables, so we have to do it manually.
PEA: Look at lab7
APE: Look at homework II solutions
```{r}
out.logit1 <- glm(model1, data = dt.insurance, family = binomial(link = 'logit'))
```


#Plots
1) Farbiger plot zwei balken, mit relativen Zahlen, nicht absoluten:
```{r, fig.height=3}
ggplot(dt.apples, aes(x = male_string)) +
  geom_bar(aes(fill = factor(buyeco_string)), position = "fill") +
  labs(x = 'Gender', y = 'Buy eco percentage', fill = 'Buy Eco') + theme_bw()
```

2) Test for predicted OLS values, if they are between 0 and 1:

```{r, fig.height=3, warning=FALSE, message=FALSE}
min(predict(out.ols))
max(predict(out.ols))

qplot(predict(out.ols), geom = 'histogram')  +
  geom_vline(xintercept = 0, col = 'Red', linetype = 2) +
  geom_vline(xintercept = 1, col = 'Red', linetype = 2) +
  labs(x = 'Probability of buying Eco Apple', y = 'Number of People') + theme_bw()
```

3) Difference in difference model
Vier trendlinien
```{r}
ggplot(data = dt.fastfood, aes(x = wage)) + geom_density() + facet_wrap( ~ state + time) +
  theme_bw()
```

Boxplot
```{r, warning=FALSE, message=FALSE, fig.height= 3}
qplot(data = dt.fastfood, x = factor(time), y = emptot
    , fill = factor(state)
    , geom = 'boxplot') + theme_bw() + xlab("time") + ylab("FTE Employment")

qplot(data  = dt.ez
        , x   = factor(year)
        , y   = uclms
       , geom = 'boxplot'
       , col  = factor(treated)) + 
        theme_bw() + theme(legend.position='bottom') + 
        labs(  x   = 'year', y   = 'Unemployment Claims', col = 'Treated')
```

4) Time trend of y, the dependent variable
```{r, warning=FALSE, message=FALSE, fig.height=3}
qplot(data = dt.ez, x = year, y = uclms ,geom = 'point') +
 theme_bw() +  theme(legend.position='bottom') + stat_smooth() +
  labs(x='year',y='Unemployment Claims', col='Entreprize zone status')
```